from collections import defaultdict
from multiprocessing import Pool

def map_function(chunk):
    word_counts = defaultdict(int)
    for line in chunk:
        for word in line.split():
            for char in word:
                if char.isalpha():
                    word_counts[char] += 1
    return word_counts

def reduce_function(results):
    word_counts_combined = defaultdict(int)
    for word_counts in results:
        for char, count in word_counts.items():
            word_counts_combined[char] += count
    return word_counts_combined

def main():
    # Get the dataset from user input
    dataset = []
    while True:
        line = input("Enter a line (or press Enter to finish): ")
        if not line:
            break
        dataset.append(line)

    # Get the number of processors from user input
    num_processors = int(input("Enter the number of processors: "))

    if len(dataset) < num_processors:
        num_processors = len(dataset)

    chunk_size = len(dataset) // num_processors
    dataset_chunks = [dataset[i:i + chunk_size] for i in range(0, len(dataset), chunk_size)]

    pool = Pool(processes=num_processors)
    results = pool.map(map_function, dataset_chunks)
    pool.close()
    pool.join()

    final_result = reduce_function(results)

    # Print the character counts
    for char, count in final_result.items():
        print(f"'{char}': {count}")

if __name__ == "__main__":
    main()


approach 2

from collections import Counter

# Sample dataset
data = [
    "This is a sample text. It contains some words.",
    "This is another sample text with some words.",
    "And here's a third text, with more words.",
]

# Mapper function
def mapper(text):
    # Split text into words and count word frequencies
    words = text.split()
    word_count = Counter(words)

    # Count the frequency of each character
    char_count = Counter("".join(words))

    return word_count, char_count

# Reducer function
def reducer(counts1, counts2):
    # Merge the counts from two mappers
    word_count = counts1[0] + counts2[0]
    char_count = counts1[1] + counts2[1]

    return word_count, char_count

# Map-Reduce operation
initial_counts = (Counter(), Counter())  # Initialize with empty counters
for text in data:
    word_count, char_count = mapper(text)
    initial_counts = reducer(initial_counts, (word_count, char_count))

# Result
word_count, char_count = initial_counts
print("Word frequencies:")
print(word_count)
print("\nCharacter frequencies:")
print(char_count)
